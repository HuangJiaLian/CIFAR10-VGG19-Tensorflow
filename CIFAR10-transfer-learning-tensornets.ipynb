{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEHVzFHCvkdg"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook presents how to train CIFAR-10 dataset on the pretrained VGG19 model. I borrow VGG19 included in tensornets package whose github repo is [here](https://github.com/taehoonlee/tensornets). Also, I will try with the different [implementation](https://github.com/machrisaa/tensorflow-vgg) of the same VGG19 architecture after done with tensornets package. \n",
    "\n",
    "The main purpose is to understand the concept of transfer learning and experience with the actual usage. I previously made an notebook to build classical CNN model to train CIFAR-10 dataset, so I can compare between the state of the art CNN model and the very basic CNN model. I am expecting VGG19 will outperform easily. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Dependency\n",
    "\n",
    "Before diving in, let's install required packages. If your system doesn't have these listed below, please run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install h5py\n",
    "!pip install scipy\n",
    "\n",
    "# scikit-image package for transforming \n",
    "# size of CIFAR-10 image into the input size for VGG19 model.\n",
    "!pip install scikit-image\n",
    "\n",
    "# tqdm package for adding progress bar like UI\n",
    "!pip install tqdm\n",
    "\n",
    "# Cython package is required to install tensornets\n",
    "!pip install Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this will install tensornets package automatically.\n",
    "# However, if you are on Windows and encountering Visual Studio Build Tool thing, please install it beforehand\n",
    "!pip install git+https://github.com/taehoonlee/tensornets.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "W06VSAiWwNW2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm \n",
    "import tarfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensornets as nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU configuration for Tensorflow\n",
    "\n",
    "If you have a very high-end GPU running on your machine, you can skip this section. I needed this configuration, and I have run the training with NVIDIA GTX 1080Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "# \"Best-fit with coalescing\" algorithm for memory allocation\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Dataset Preparation\n",
    "\n",
    "This is the same step as described in my other github [repo](https://github.com/deep-diver/CIFAR10-img-classification-tensorflow). If you are more interested in this step, please read the detailed explanation from the link. Otherwise, you can skip to the next section.\n",
    "\n",
    "## Download CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 16122,
     "status": "ok",
     "timestamp": 1526728322562,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "yuLcGSrRwelh",
    "outputId": "012a8faf-9f47-4865-8279-f05213c7b358"
   },
   "outputs": [],
   "source": [
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DownloadProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "\"\"\" \n",
    "    check if the data (zip) file is already downloaded\n",
    "    if not, download it from \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" and save as cifar-10-python.tar.gz\n",
    "\"\"\"\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load raw data and reshape the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9hAxLUckxBwR"
   },
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot encoding method for label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "hipGIs1BxJiK"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the modified input(feature) and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xz29Y5E8xJe6"
   },
   "outputs": [],
   "source": [
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "        index_of_validation = int(len(features) * 0.1)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(normalize, one_hot_encode,\n",
    "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
    "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
    "        # - take 10% of the whold dataset of the batch\n",
    "        # - add them into a list of\n",
    "        #   - valid_features\n",
    "        #   - valid_labels\n",
    "        valid_features.extend(features[-index_of_validation:])\n",
    "        valid_labels.extend(labels[-index_of_validation:])\n",
    "\n",
    "    # preprocess the all stacked validation dataset\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(valid_features), np.array(valid_labels),\n",
    "                         'preprocess_validation.p')\n",
    "\n",
    "    # load the test dataset\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # preprocess the testing data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all testing data\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(test_features), np.array(test_labels),\n",
    "                         'preprocess_testing.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "onL8b7jZxjGq"
   },
   "outputs": [],
   "source": [
    "preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning the model for CIFAR-10\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qIGZ-8GexjBF"
   },
   "outputs": [],
   "source": [
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define input (feature) and output (label)\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/321232691/figure/fig4/AS:563669300121600@1511400641052/The-figure-maps-of-VGG19-in-our-approach-Blue-ones-are-got-from-convolutional-layer-and.ppm\"/>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "__VGG19 Architecture__\n",
    "</p>\n",
    "<p style=\"text-align:center;\">\n",
    "(borrowed from [OREILLY](https://www.safaribooksonline.com/library/view/machine-learning-with/9781786462961/21266fa5-9e3b-4f9e-b3c6-2ca27a8f8c12.xhtml))\n",
    "</p>\n",
    "\n",
    "VGG models described in the [original paper](https://arxiv.org/pdf/1409.1556.pdf) are trained with images whose size is 224x224x3. This can not be changed, so the input image for the transfer learning task should have the same image size. For the output, CIFAR-10 contains 10 categorical image data which makes the output size 10 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZEr9SKaPxi1z"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name='input_x')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10), name='output_y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters\n",
    "\n",
    "- You don't need many epochs since this is transfer learning.\n",
    "- you can increase the batch size if you have a very high-end GPU running. 32 is the maximum value I could try with NVIDIA GTX 1080Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qCivsIqkHGLn"
   },
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VGG19 model, Define loss, train, and accuracy tensor/Operation\n",
    "\n",
    "The first step is to predefined VGG19 model. \n",
    "- if you want to run the model as it is, just pass the input placeholder.\n",
    "- if you want to train on your own image dataset, set is_training=True, and classes=# of class\n",
    "\n",
    "nets.VGG19 returns the final layer of the VGG19 which is softmax. If you know, tensorflow comes with tf.nn.softmax_cross_entropy_with_logits function, and this applies softmax and cross entropy together. However, nets.VGG19 returns the layer already applied with softmax, so we need only cross entropy. That can be achieved by tf.losses.softmax_cross_entropy function.\n",
    "\n",
    "In your choice, you can choose your favorite optimizer. I am going to use Adam optimizer since it is known to work moderate for most of deep learning problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "XHpQqG9dxivw"
   },
   "outputs": [],
   "source": [
    "logits = nets.VGG19(x, is_training=True, classes=10)\n",
    "model = tf.identity(logits, name='logits')\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(y, logits)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YjzH1tD5HafW"
   },
   "source": [
    "## Get Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "fXXUD381xioX"
   },
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of each CIFAR-10 image is 32x32, and VGG19 takes input image sizes 224x224 which is incompatible. Each CIFAR-10 image should be resized so that it can be fed into the VGG19 model. \n",
    "\n",
    "skimage.transform.resize function does the trick. It takes parameters..\n",
    "- takes a numpy matrix representation of an image\n",
    "- image size to be transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "X0ub-PEPHF7x"
   },
   "outputs": [],
   "source": [
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "    \n",
    "    tmpFeatures = []\n",
    "    \n",
    "    for feature in features:\n",
    "        tmpFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "        tmpFeatures.append(tmpFeature)\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(tmpFeatures, labels, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get inputs for validation\n",
    "\n",
    "The same process from load_preprocess_training_batch is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "D3M7KvDKHGDD"
   },
   "outputs": [],
   "source": [
    "tmpValidFeatures = []\n",
    "\n",
    "for feature in valid_features:\n",
    "    tmpValidFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "    tmpValidFeatures.append(tmpValidFeature)\n",
    "    \n",
    "tmpValidFeatures = np.array(tmpValidFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5,000 images in a batch is huge to be trained. If you have a very high-end GPU card, you can try all images at once, but I will go with batch validation, then calculate the mean of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1526729611931,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "uf4tGgBHJUq0",
    "outputId": "eb99c4e7-d188-43a3-d797-424563b65625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(tmpValidFeatures.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 651,
     "status": "error",
     "timestamp": 1526729647966,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "jclFs6j0HGJV",
    "outputId": "3c7fce73-dc72-44a3-eec1-8923ac9fc0ab",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "global_variables_initializer ... done ...\n",
      "model.pretrained ... done ... \n",
      "starting training ... \n",
      "Epoch  1, CIFAR-10 Batch 1:  Validation Accuracy: 0.510000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Validation Accuracy: 0.719000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Validation Accuracy: 0.770200\n",
      "Epoch  1, CIFAR-10 Batch 4:  Validation Accuracy: 0.814000\n",
      "Epoch  1, CIFAR-10 Batch 5:  Validation Accuracy: 0.832000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Validation Accuracy: 0.841600\n",
      "Epoch  2, CIFAR-10 Batch 2:  Validation Accuracy: 0.850000\n",
      "Epoch  2, CIFAR-10 Batch 3:  Validation Accuracy: 0.868000\n",
      "Epoch  2, CIFAR-10 Batch 4:  Validation Accuracy: 0.856600\n",
      "Epoch  2, CIFAR-10 Batch 5:  Validation Accuracy: 0.857400\n",
      "Epoch  3, CIFAR-10 Batch 1:  Validation Accuracy: 0.867600\n",
      "Epoch  3, CIFAR-10 Batch 2:  Validation Accuracy: 0.874400\n",
      "Epoch  3, CIFAR-10 Batch 3:  Validation Accuracy: 0.887600\n",
      "Epoch  3, CIFAR-10 Batch 4:  Validation Accuracy: 0.867200\n",
      "Epoch  3, CIFAR-10 Batch 5:  Validation Accuracy: 0.888400\n",
      "Epoch  4, CIFAR-10 Batch 1:  Validation Accuracy: 0.865400\n",
      "Epoch  4, CIFAR-10 Batch 2:  Validation Accuracy: 0.901200\n",
      "Epoch  4, CIFAR-10 Batch 3:  Validation Accuracy: 0.863200\n",
      "Epoch  4, CIFAR-10 Batch 4:  Validation Accuracy: 0.885600\n",
      "Epoch  4, CIFAR-10 Batch 5:  Validation Accuracy: 0.891400\n",
      "Epoch  5, CIFAR-10 Batch 1:  Validation Accuracy: 0.874400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Validation Accuracy: 0.901200\n",
      "Epoch  5, CIFAR-10 Batch 3:  Validation Accuracy: 0.896000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Validation Accuracy: 0.886400\n",
      "Epoch  5, CIFAR-10 Batch 5:  Validation Accuracy: 0.910000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Validation Accuracy: 0.899800\n",
      "Epoch  6, CIFAR-10 Batch 2:  Validation Accuracy: 0.901000\n",
      "Epoch  6, CIFAR-10 Batch 3:  Validation Accuracy: 0.899600\n",
      "Epoch  6, CIFAR-10 Batch 4:  Validation Accuracy: 0.913600\n",
      "Epoch  6, CIFAR-10 Batch 5:  Validation Accuracy: 0.903600\n",
      "Epoch  7, CIFAR-10 Batch 1:  Validation Accuracy: 0.911600\n",
      "Epoch  7, CIFAR-10 Batch 2:  Validation Accuracy: 0.916200\n",
      "Epoch  7, CIFAR-10 Batch 3:  Validation Accuracy: 0.914400\n",
      "Epoch  7, CIFAR-10 Batch 4:  Validation Accuracy: 0.908200\n",
      "Epoch  7, CIFAR-10 Batch 5:  Validation Accuracy: 0.915200\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:    \n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('global_variables_initializer ... done ...')\n",
    "    sess.run(logits.pretrained())\n",
    "    print('model.pretrained ... done ... ')    \n",
    "    \n",
    "    # Training cycle\n",
    "    print('starting training ... ')\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                sess.run(train, {x: batch_features, y: batch_labels})\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            \n",
    "            # calculate the mean accuracy over all validation dataset\n",
    "            valid_acc = 0\n",
    "            for batch_valid_features, batch_valid_labels in batch_features_labels(tmpValidFeatures, valid_labels, batch_size):\n",
    "                valid_acc += sess.run(accuracy, {x:batch_valid_features, y:batch_valid_labels})\n",
    "            \n",
    "            tmp_num = tmpValidFeatures.shape[0]/batch_size\n",
    "            print('Validation Accuracy: {:.6f}'.format(valid_acc/tmp_num))\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model over random sample images\n",
    "\n",
    "## mapping label index to label name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "cw8naOjVxB2c"
   },
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display prediction results (match or not?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "elh_ZDAyHGGg"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def display_image_predictions(features, labels, predictions):\n",
    "    n_classes = 10\n",
    "    label_names = load_label_names()\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "   \n",
    "    for image_i, (feature, label_id, prediction) in enumerate(zip(features, label_ids, predictions)):\n",
    "        correct_name = label_names[label_id]\n",
    "        pred_name = label_names[np.argmax(prediction)]\n",
    "        \n",
    "        is_match = 'False'        \n",
    "        \n",
    "        if np.argmax(prediction) == label_id:\n",
    "            is_match = 'True'\n",
    "            \n",
    "        predictions_array = []\n",
    "        \n",
    "        for index, pred_value in enumerate(prediction):\n",
    "            tmp_pred_name = label_names[index]\n",
    "            predictions_array.append({tmp_pred_name : pred_value})\n",
    "        \n",
    "        print('[{}] ground truth: {}, predicted result: {} | {}'.format(image_i, correct_name, pred_name, is_match))\n",
    "        print('\\t- {}\\n'.format(predictions_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features, test_labels = pickle.load(open('preprocess_testing.p', mode='rb'))\n",
    "tmpFeatures = []\n",
    "\n",
    "for feature in test_features:\n",
    "    tmpFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "    tmpFeatures.append(tmpFeature)\n",
    "\n",
    "tmpFeatures = np.asarray(tmpFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yT3TlbjrHGA8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.9185907643312102\n",
      "\n",
      "[0] ground truth: cat, predicted result: cat | True\n",
      "\t- [{'airplane': 0.08533675}, {'automobile': 0.08533675}, {'bird': 0.08533675}, {'cat': 0.23196931}, {'deer': 0.08533675}, {'dog': 0.08533677}, {'frog': 0.08533675}, {'horse': 0.08533675}, {'ship': 0.08533675}, {'truck': 0.08533675}]\n",
      "\n",
      "[1] ground truth: truck, predicted result: truck | True\n",
      "\t- [{'airplane': 0.0853368}, {'automobile': 0.08533726}, {'bird': 0.0853368}, {'cat': 0.0853368}, {'deer': 0.0853368}, {'dog': 0.0853368}, {'frog': 0.0853368}, {'horse': 0.0853368}, {'ship': 0.0853368}, {'truck': 0.23196818}]\n",
      "\n",
      "[2] ground truth: bird, predicted result: bird | True\n",
      "\t- [{'airplane': 0.085336745}, {'automobile': 0.085336745}, {'bird': 0.23196931}, {'cat': 0.085336745}, {'deer': 0.085336745}, {'dog': 0.085336745}, {'frog': 0.085336745}, {'horse': 0.085336745}, {'ship': 0.085336745}, {'truck': 0.085336745}]\n",
      "\n",
      "[3] ground truth: dog, predicted result: dog | True\n",
      "\t- [{'airplane': 0.08533676}, {'automobile': 0.08533676}, {'bird': 0.08533676}, {'cat': 0.08533685}, {'deer': 0.08533676}, {'dog': 0.2319691}, {'frog': 0.08533676}, {'horse': 0.08533676}, {'ship': 0.08533676}, {'truck': 0.08533676}]\n",
      "\n",
      "[4] ground truth: deer, predicted result: deer | True\n",
      "\t- [{'airplane': 0.0856839}, {'automobile': 0.08568432}, {'bird': 0.08579623}, {'cat': 0.08799722}, {'deer': 0.22637448}, {'dog': 0.08568428}, {'frog': 0.08568712}, {'horse': 0.085693955}, {'ship': 0.08570021}, {'truck': 0.085698254}]\n",
      "\n",
      "[5] ground truth: deer, predicted result: deer | True\n",
      "\t- [{'airplane': 0.085336745}, {'automobile': 0.085336745}, {'bird': 0.085336745}, {'cat': 0.085336745}, {'deer': 0.23196931}, {'dog': 0.085336745}, {'frog': 0.085336745}, {'horse': 0.085336745}, {'ship': 0.085336745}, {'truck': 0.085336745}]\n",
      "\n",
      "[6] ground truth: airplane, predicted result: airplane | True\n",
      "\t- [{'airplane': 0.23196934}, {'automobile': 0.08533675}, {'bird': 0.08533675}, {'cat': 0.08533675}, {'deer': 0.08533675}, {'dog': 0.08533675}, {'frog': 0.08533675}, {'horse': 0.08533675}, {'ship': 0.08533675}, {'truck': 0.08533675}]\n",
      "\n",
      "[7] ground truth: ship, predicted result: ship | True\n",
      "\t- [{'airplane': 0.08534732}, {'automobile': 0.08533991}, {'bird': 0.08533991}, {'cat': 0.0853531}, {'deer': 0.08534003}, {'dog': 0.08533993}, {'frog': 0.08533991}, {'horse': 0.085339986}, {'ship': 0.23191914}, {'truck': 0.08534076}]\n",
      "\n",
      "[8] ground truth: horse, predicted result: horse | True\n",
      "\t- [{'airplane': 0.08533738}, {'automobile': 0.08533738}, {'bird': 0.08533738}, {'cat': 0.08533738}, {'deer': 0.08533738}, {'dog': 0.08534172}, {'frog': 0.08533738}, {'horse': 0.23195924}, {'ship': 0.08533738}, {'truck': 0.08533738}]\n",
      "\n",
      "[9] ground truth: truck, predicted result: truck | True\n",
      "\t- [{'airplane': 0.085368685}, {'automobile': 0.08558747}, {'bird': 0.085368685}, {'cat': 0.085368685}, {'deer': 0.085368685}, {'dog': 0.085368685}, {'frog': 0.085368685}, {'horse': 0.085368685}, {'ship': 0.085368685}, {'truck': 0.23146296}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import random\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "batch_size = 64\n",
    "n_samples = 10\n",
    "top_n_predictions = 5\n",
    "\n",
    "def test_model(tmpFeatures):\n",
    "    loaded_graph = tf.Graph()\n",
    "    \n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        loaded_x = loaded_graph.get_tensor_by_name('input_x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('output_y:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in batch_features_labels(tmpFeatures, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        \n",
    "        tmpTestFeatures = []\n",
    "    \n",
    "        for feature in random_test_features:\n",
    "            tmpFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "            tmpTestFeatures.append(tmpFeature)\n",
    "           \n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.softmax(loaded_logits),\n",
    "            feed_dict={loaded_x: tmpTestFeatures, loaded_y: random_test_labels})\n",
    "        \n",
    "        display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "test_model(tmpFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dFqUGLUixBkz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "안녕하세요, Colaboratory입니다의 사본",
   "provenance": [
    {
     "file_id": "/v2/external/notebooks/welcome.ipynb",
     "timestamp": 1526729659664
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "(Python) tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
