{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEHVzFHCvkdg"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook presents how to train CIFAR-10 dataset on the pretrained VGG16 model. I borrow VGG16 included in tensornets package whose github repo is [here](https://github.com/taehoonlee/tensornets). Also, I will try with the different [implementation](https://github.com/machrisaa/tensorflow-vgg) of the same VGG16 architecture after done with tensornets package. \n",
    "\n",
    "The main purpose is to understand the concept of transfer learning and experience with the actual usage. I previously made an notebook to build classical CNN model to train CIFAR-10 dataset, so I can compare between the state of the art CNN model and the very basic CNN model. I am expecting VGG16 will outperform easily. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Dependency\n",
    "\n",
    "Before diving in, let's install required packages. If your system doesn't have these listed below, please run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py\n",
    "!pip install scipy\n",
    "\n",
    "# scikit-image package for transforming \n",
    "# size of CIFAR-10 image into the input size for VGG16 model.\n",
    "!pip install scikit-image\n",
    "\n",
    "# tqdm package for adding progress bar like UI\n",
    "!pip install tqdm\n",
    "\n",
    "# Cython package is required to install tensornets\n",
    "!pip install Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will install tensornets package automatically.\n",
    "# However, if you are on Windows and encountering Visual Studio Build Tool thing, please install it beforehand\n",
    "!pip install git+https://github.com/taehoonlee/tensornets.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Dataset Preparation\n",
    "\n",
    "This is the same step as described in my other github [repo](https://github.com/deep-diver/CIFAR10-img-classification-tensorflow). If you are interested in this step, please read the detailed explanation from the link. Otherwise, you can skip to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "W06VSAiWwNW2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm \n",
    "import tarfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensornets as nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16122,
     "status": "ok",
     "timestamp": 1526728322562,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "yuLcGSrRwelh",
    "outputId": "012a8faf-9f47-4865-8279-f05213c7b358"
   },
   "outputs": [],
   "source": [
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DownloadProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "\"\"\" \n",
    "    check if the data (zip) file is already downloaded\n",
    "    if not, download it from \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" and save as cifar-10-python.tar.gz\n",
    "\"\"\"\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cw8naOjVxB2c"
   },
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9hAxLUckxBwR"
   },
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v1BkPhJtxJlo"
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x \n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hipGIs1BxJiK"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xz29Y5E8xJe6"
   },
   "outputs": [],
   "source": [
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "    features = normalize(features)\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "        index_of_validation = int(len(features) * 0.1)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(normalize, one_hot_encode,\n",
    "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
    "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
    "        # - take 10% of the whold dataset of the batch\n",
    "        # - add them into a list of\n",
    "        #   - valid_features\n",
    "        #   - valid_labels\n",
    "        valid_features.extend(features[-index_of_validation:])\n",
    "        valid_labels.extend(labels[-index_of_validation:])\n",
    "\n",
    "    # preprocess the all stacked validation dataset\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(valid_features), np.array(valid_labels),\n",
    "                         'preprocess_validation.p')\n",
    "\n",
    "    # load the test dataset\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # preprocess the testing data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all testing data\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(test_features), np.array(test_labels),\n",
    "                         'preprocess_training.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "onL8b7jZxjGq"
   },
   "outputs": [],
   "source": [
    "preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qIGZ-8GexjBF"
   },
   "outputs": [],
   "source": [
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input (feature) and output (label)\n",
    "\n",
    "<img src=\"https://www.safaribooksonline.com/library/view/machine-learning-with/9781786462961/assets/f36fb94f-8824-43f8-a44b-e437972b52ed.png\"/>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "__VGG16 Architecture__\n",
    "</p>\n",
    "<p style=\"text-align:center;\">\n",
    "(borrowed from [OREILLY](https://www.safaribooksonline.com/library/view/machine-learning-with/9781786462961/21266fa5-9e3b-4f9e-b3c6-2ca27a8f8c12.xhtml))\n",
    "</p>\n",
    "\n",
    "VGG models described in the [original paper](https://arxiv.org/pdf/1409.1556.pdf) are trained with images whose size is 224x224x3. This can not be changed, so the input image for the transfer learning task should have the same image size. For the output, CIFAR-10 contains 10 categorical image data which makes the output size 10 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZEr9SKaPxi1z"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name='input_x')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10), name='output_y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load VGG16 model, Define loss, train, and accuracy tensor/Operation\n",
    "\n",
    "The first step is to predefined VGG16 model. \n",
    "- if you want to run the model as it is, just pass the input placeholder.\n",
    "- if you want to train on your own image dataset, set is_training=True, and classes=# of class\n",
    "\n",
    "nets.VGG16 returns the final layer of the VGG16 which is softmax. If you know, tensorflow comes with tf.nn.softmax_cross_entropy_with_logits function, and this applies softmax and cross entropy together. However, nets.VGG16 returns the layer already applied with softmax, so we need only cross entropy. That can be achieved by tf.losses.softmax_cross_entropy function.\n",
    "\n",
    "In your choice, you can choose your favorite optimizer. I am going to use Adam optimizer since it is known to work moderate for most of deep learning problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XHpQqG9dxivw"
   },
   "outputs": [],
   "source": [
    "logits = nets.VGG16(x, is_training=True, classes=10)\n",
    "model = tf.identity(logits, name='logits')\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(y, logits)\n",
    "train = tf.train.AdamOptimizer(learning_rate=1e-5).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YjzH1tD5HafW"
   },
   "source": [
    "# Get Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fXXUD381xioX"
   },
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of each CIFAR-10 image is 32x32, and VGG16 takes input image sizes 224x224 which is incompatible. Each CIFAR-10 image should be resized so that it can be fed into the VGG16 model. \n",
    "\n",
    "skimage.transform.resize function does the trick. It takes parameters..\n",
    "- takes a numpy matrix representation of an image\n",
    "- image size to be transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "X0ub-PEPHF7x"
   },
   "outputs": [],
   "source": [
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "    \n",
    "    tmpFeatures = []\n",
    "    \n",
    "    for feature in features:\n",
    "        tmpFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "        tmpFeatures.append(tmpFeature)\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(tmpFeatures, labels, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get inputs for validation\n",
    "\n",
    "The same process from load_preprocess_training_batch is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "D3M7KvDKHGDD"
   },
   "outputs": [],
   "source": [
    "tmpValidFeatures = []\n",
    "\n",
    "for feature in valid_features:\n",
    "    tmpValidFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "    tmpValidFeatures.append(tmpValidFeature)\n",
    "    \n",
    "tmpValidFeatures = np.array(tmpValidFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5,000 images in a batch is huge to be trained. If you have a very high-end GPU card, you can try more images, but I will go with only 100 of them. By the way, you can also run the batch validation process and calculate the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1526729611931,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "uf4tGgBHJUq0",
    "outputId": "eb99c4e7-d188-43a3-d797-424563b65625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 224, 224, 3)\n",
      "(100, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(tmpValidFeatures.shape)\n",
    "tmpValidFeatures = tmpValidFeatures[:100]\n",
    "valid_labels = valid_labels[:100]\n",
    "print(tmpValidFeatures.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Stats of Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "s8GAbibSKOQL"
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, loss, accuracy):\n",
    "    valid_acc = sess.run(accuracy, \n",
    "                         feed_dict={\n",
    "                             x: tmpValidFeatures,\n",
    "                             y: valid_labels\n",
    "                         })\n",
    "    \n",
    "    print('Validation Accuracy: {:.6f}'.format(valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qCivsIqkHGLn"
   },
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 651,
     "status": "error",
     "timestamp": 1526729647966,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "jclFs6j0HGJV",
    "outputId": "3c7fce73-dc72-44a3-eec1-8923ac9fc0ab",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "global_variables_initializer ... done ...\n",
      "model.pretrained ... done ... \n",
      "starting training ... \n",
      "Epoch  1, CIFAR-10 Batch 1:  Validation Accuracy: 0.530000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Validation Accuracy: 0.610000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Validation Accuracy: 0.750000\n",
      "Epoch  1, CIFAR-10 Batch 4:  Validation Accuracy: 0.720000\n",
      "Epoch  1, CIFAR-10 Batch 5:  Validation Accuracy: 0.770000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Validation Accuracy: 0.780000\n",
      "Epoch  2, CIFAR-10 Batch 2:  Validation Accuracy: 0.800000\n",
      "Epoch  2, CIFAR-10 Batch 3:  Validation Accuracy: 0.800000\n",
      "Epoch  2, CIFAR-10 Batch 4:  Validation Accuracy: 0.810000\n",
      "Epoch  2, CIFAR-10 Batch 5:  Validation Accuracy: 0.810000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Validation Accuracy: 0.770000\n",
      "Epoch  3, CIFAR-10 Batch 2:  Validation Accuracy: 0.810000\n",
      "Epoch  3, CIFAR-10 Batch 3:  Validation Accuracy: 0.830000\n",
      "Epoch  3, CIFAR-10 Batch 4:  Validation Accuracy: 0.860000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Validation Accuracy: 0.830000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Validation Accuracy: 0.780000\n",
      "Epoch  4, CIFAR-10 Batch 2:  Validation Accuracy: 0.830000\n",
      "Epoch  4, CIFAR-10 Batch 3:  Validation Accuracy: 0.820000\n",
      "Epoch  4, CIFAR-10 Batch 4:  Validation Accuracy: 0.850000\n",
      "Epoch  4, CIFAR-10 Batch 5:  Validation Accuracy: 0.790000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Validation Accuracy: 0.800000\n",
      "Epoch  5, CIFAR-10 Batch 2:  Validation Accuracy: 0.820000\n",
      "Epoch  5, CIFAR-10 Batch 3:  Validation Accuracy: 0.860000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Validation Accuracy: 0.850000\n",
      "Epoch  5, CIFAR-10 Batch 5:  Validation Accuracy: 0.830000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Validation Accuracy: 0.860000\n",
      "Epoch  6, CIFAR-10 Batch 2:  Validation Accuracy: 0.820000\n",
      "Epoch  6, CIFAR-10 Batch 3:  Validation Accuracy: 0.860000\n",
      "Epoch  6, CIFAR-10 Batch 4:  Validation Accuracy: 0.860000\n",
      "Epoch  6, CIFAR-10 Batch 5:  Validation Accuracy: 0.840000\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:    \n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('global_variables_initializer ... done ...')\n",
    "    sess.run(logits.pretrained())\n",
    "    print('model.pretrained ... done ... ')    \n",
    "    \n",
    "    # Training cycle\n",
    "    print('starting training ... ')\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                sess.run(train, {x: batch_features, y: batch_labels})\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, loss, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "elh_ZDAyHGGg"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def display_image_predictions(features, labels, predictions):\n",
    "    n_classes = 10\n",
    "    label_names = load_label_names()\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "#     fig, axies = plt.subplots(nrows=4, ncols=2)\n",
    "#     fig.tight_layout()\n",
    "#     fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "\n",
    "#     n_predictions = 3\n",
    "#     margin = 0.05\n",
    "#     ind = np.arange(n_predictions)\n",
    "#     width = (1. - 2. * margin) / n_predictions\n",
    "\n",
    "#     print('predictions: ', predictions)\n",
    "    \n",
    "    for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n",
    "        pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
    "        correct_name = label_names[label_id]\n",
    "        pred_name = label_names[np.argmax(pred_indicies)]\n",
    "\n",
    "            \n",
    "        print('[{}] ground truth: {}, predicted result: {}\\n'.format(image_i, correct_name, pred_name))\n",
    "#             axies[image_i][0].imshow(feature*255)\n",
    "#             axies[image_i][0].set_title(correct_name)\n",
    "#             axies[image_i][0].set_axis_off()\n",
    "\n",
    "#             axies[image_i][1].barh(ind + margin, pred_values[::-1], width)\n",
    "#             axies[image_i][1].set_yticks(ind + margin)\n",
    "#             axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "#             axies[image_i][1].set_xticks([0, 0.5, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "tmpFeatures = []\n",
    "\n",
    "for feature in test_features:\n",
    "    tmpFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "    tmpFeatures.append(tmpFeature)\n",
    "\n",
    "tmpFeatures = np.asarray(tmpFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(tmpFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yT3TlbjrHGA8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\\image_classification\n",
      "Testing Accuracy: 0.9011743630573248\n",
      "\n",
      "[0] ground truth: deer, predicted result: airplane\n",
      "\n",
      "[1] ground truth: dog, predicted result: airplane\n",
      "\n",
      "[2] ground truth: cat, predicted result: bird\n",
      "\n",
      "[3] ground truth: automobile, predicted result: deer\n",
      "\n",
      "[4] ground truth: bird, predicted result: deer\n",
      "\n",
      "[5] ground truth: frog, predicted result: airplane\n",
      "\n",
      "[6] ground truth: frog, predicted result: cat\n",
      "\n",
      "[7] ground truth: dog, predicted result: bird\n",
      "\n",
      "[8] ground truth: truck, predicted result: airplane\n",
      "\n",
      "[9] ground truth: bird, predicted result: bird\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import random\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "batch_size = 64\n",
    "n_samples = 10\n",
    "top_n_predictions = 5\n",
    "\n",
    "def test_model(tmpFeatures):\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(save_model_path))\n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in batch_features_labels(tmpFeatures, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                accuracy,\n",
    "                feed_dict={x: train_feature_batch, y: train_label_batch})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        \n",
    "        tmpTestFeatures = []\n",
    "    \n",
    "        for feature in random_test_features:\n",
    "            tmpFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "            tmpTestFeatures.append(tmpFeature)\n",
    "           \n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(model), top_n_predictions),\n",
    "            feed_dict={x: tmpTestFeatures, y: random_test_labels})\n",
    "        \n",
    "        display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model(tmpFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dFqUGLUixBkz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "안녕하세요, Colaboratory입니다의 사본",
   "provenance": [
    {
     "file_id": "/v2/external/notebooks/welcome.ipynb",
     "timestamp": 1526729659664
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "(Python) tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
